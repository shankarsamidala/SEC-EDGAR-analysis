{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing require packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import cmudict\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Adhya\\\\Desktop\\\\Black offer'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing dats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"cik_list.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding link to each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SECFNAME']= \"https://www.sec.gov/Archives/\" +data['SECFNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data')\n",
    "os.mkdir('data22')\n",
    "os.mkdir('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of stopwords files From web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=['https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Generic.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Names.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_DatesandNumbers.txt',\n",
    "       'https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Geographic.txt','https://www3.nd.edu/~mcdonald/Data/ND_Stop_Words_Currencies.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting stopwords data from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scraping stop words from web\n",
    "for i in range(len(link)):\n",
    "    req=requests.get(link[i],timeout=4)\n",
    "    sleep(1)\n",
    "    soup=BeautifulSoup(req.text,'html.parser')\n",
    "    s=open('stopwords/stopwords_'+str(i)+'.txt',\"w+\")\n",
    "    lst=re.findall('\\w*[a-zA-Z]',soup.get_text().lower())\n",
    "    for a in lst:\n",
    "        s.write(a+' ')\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data From web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping data from web\n",
    "for i in range(len(data)):\n",
    "    req=requests.get(data['SECFNAME'][i])\n",
    "    sleep(2.5)\n",
    "    s=open('dt/'+str(i)+'.txt',\"w+\",encoding=\"utf-8\")\n",
    "    s.write(req.text)\n",
    "    s.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the require sections are present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking which sections are present in the data\n",
    "\n",
    "scores=[]\n",
    "for i in range(len(data)):\n",
    "    s=open('dt/'+str(i)+'.txt',\"r\",encoding=\"utf-8\")\n",
    "    text=s.read()\n",
    "    s.close()\n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "    score=''\n",
    "    find_text=soup.get_text().lower()\n",
    "    if \"management's discussion and analysis\" in find_text:\n",
    "        score+='1'\n",
    "    if \"quantitative and qualitative disclosures about market risk\" in find_text:\n",
    "        score+='2'\n",
    "    if \"risk factors\" in find_text:\n",
    "        score+='3'\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving data into a particular file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    x=open('dt/'+str(i)+'.txt','r',encoding='utf-8')\n",
    "    text=x.read().lower()\n",
    "    x.close()\n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "\n",
    "    if '1'in scores[i]:\n",
    "        text1=''\n",
    "        for a in soup(text=re.compile(\"management's discussion and analysis\")):\n",
    "            text1=text1+''+str(a.parent)\n",
    "            x1=open('dt2/'+str(i)+'_text1.txt',\"w+\",encoding=\"utf-8\")\n",
    "            x1.write(text1)\n",
    "            x1.close()\n",
    "    if '2' in scores[i]:\n",
    "        text2=''\n",
    "        for a in soup(text=re.compile(\"quantitative and qualitative disclosures about market risk\")):\n",
    "            text2=text2+''+str(a.parent)\n",
    "            y1=open('dt2/'+str(i)+'_text2.txt',\"w+\",encoding=\"utf-8\")\n",
    "            y1.write(text2)\n",
    "            y1.close()\n",
    "    if '3'in scores[i]:\n",
    "        text3=''\n",
    "        for a in soup(text=re.compile(\"risk factors\")):\n",
    "            text3=text3+''+str(a.parent)\n",
    "            z1=open('dt2/'+str(i)+'_text3.txt',\"w+\",encoding=\"utf-8\")\n",
    "            z1.write(text3)\n",
    "            z1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
