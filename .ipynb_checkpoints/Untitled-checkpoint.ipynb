{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Adhya\\\\Desktop\\\\Black offer'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_excel(\"cik_list.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(152, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SECFNAME']= \"https://www.sec.gov/Archives/\" +data['SECFNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('data')\n",
    "os.mkdir('data22')\n",
    "os.mkdir('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapping data\n",
    "for i in range(len(data)):\n",
    "    f=requests.get(data['SECFNAME'][i])\n",
    "    sleep(2.5)\n",
    "    text=f.text\n",
    "    f_obj=open('data/'+str(i)+'.txt','w+',encoding='utf-8')\n",
    "    f_obj.write(text)\n",
    "    f_obj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking which sections are present in a document\n",
    "scores=[]#this list describes the presence or absence of given sections in a document or report\n",
    "for i in range(len(data)):\n",
    "    f_obj=open('data/'+str(i)+'.txt','r',encoding='utf-8')\n",
    "    text=f_obj.read()\n",
    "    f_obj.close()\n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "    score=''\n",
    "    page_text=soup.get_text().lower()\n",
    "    if \"management's discussion and analysis\" in page_text:\n",
    "        score+='1'\n",
    "    if \"quantitative and qualitative disclosures about market risk\" in page_text:\n",
    "        score+='2'\n",
    "    if \"risk factors\" in page_text:\n",
    "        score+='3'\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    f_obj=open('data/'+str(i)+'.txt','r',encoding='utf-8')\n",
    "    text=f_obj.read().lower()\n",
    "    f_obj.close()\n",
    "    soup=BeautifulSoup(text,'html.parser')\n",
    "    if '1' in scores[i]:\n",
    "        text1=''\n",
    "        for elem in soup(text=re.compile(\"management's discussion and analysis\")):\n",
    "            text1=text1+' '+str(elem.parent)\n",
    "            f_obj1=open('data2/'+str(i)+'_text1.txt','w+',encoding='utf-8')\n",
    "            f_obj1.write(text1)\n",
    "            f_obj1.close()\n",
    "    if '2' in scores[i]:\n",
    "        text2=''\n",
    "        for elem in soup(text=re.compile(\"quantitative and qualitative disclosures about market risk\")):\n",
    "            text2=text2+' '+str(elem.parent)\n",
    "            f_obj1=open('data2/'+str(i)+'_text2.txt','w+',encoding='utf-8')\n",
    "            f_obj1.write(text2)\n",
    "            f_obj1.close()\n",
    "    if '3' in scores[i]:\n",
    "        text3=''\n",
    "        for elem in soup(text=re.compile(\"risk factors\")):\n",
    "            text3=text3+' '+str(elem.parent)\n",
    "            f_obj1=open('data2/'+str(i)+'_text3.txt','w+',encoding='utf-8')\n",
    "            f_obj1.write(text3)\n",
    "            f_obj1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
